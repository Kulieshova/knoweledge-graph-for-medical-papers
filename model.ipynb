{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baafa616",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "baafa616",
    "outputId": "f3fb4086-6ca5-4e2b-9586-871a4603e3a2"
   },
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install pymupdf # Install PyMuPDF which includes the correct fitz module.\n",
    "!pip install -U pip setuptools wheel\n",
    "!pip uninstall -U spacy\n",
    "!pip install -U spacy==3.7.6\n",
    "import spacy\n",
    "import os\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73265cc5-9e50-48e4-824d-5c858a6a92e6",
   "metadata": {
    "id": "73265cc5-9e50-48e4-824d-5c858a6a92e6"
   },
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import os\n",
    "start='abstract'\n",
    "end='references'\n",
    "\n",
    "start_page=0\n",
    "main_dir=\"/content/Docs/\"\n",
    "def find_index(text,target):\n",
    "    try:\n",
    "        return text.index(target)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "for files in os.listdir(main_dir):\n",
    "    passage=\"\"\n",
    "    found=False\n",
    "    path=main_dir+files\n",
    "    if files[-3:]!=\"pdf\":\n",
    "        continue\n",
    "    reader = PdfReader(path)\n",
    "    number_of_pages = len(reader.pages)\n",
    "    for page_num in range(number_of_pages):\n",
    "        page = reader.pages[page_num]\n",
    "        text = [texts.lower() for texts in page.extract_text().split()]\n",
    "        start_idx=find_index(text,start)+1\n",
    "        end_idx=find_index(text,end)\n",
    "        if found:\n",
    "            if start_idx == -1 and end_idx==-1:\n",
    "                passage += \" \".join(text)\n",
    "            elif end_idx != -1 and start_idx == -1:\n",
    "                passage += \" \".join(text[:end_idx])\n",
    "            else:\n",
    "                passage += \" \".join(text[start_idx:end_idx])\n",
    "        elif not found:\n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                found=True\n",
    "                passage += \" \".join(text[start_idx:end_idx])\n",
    "            elif start_idx == -1 and end_idx != -1:\n",
    "                found=True\n",
    "                passage += \" \".join(text[:end_idx])\n",
    "            elif start_idx == -1 and end_idx == -1:\n",
    "                continue\n",
    "            else:\n",
    "                found=True\n",
    "                passage += \" \".join(text[start_idx:])\n",
    "    with open(main_dir+\"text/\"+files[:-3]+\".txt\", 'w') as f:\n",
    "        f.write(passage)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ciT7WPzCeFh6",
   "metadata": {
    "id": "ciT7WPzCeFh6"
   },
   "source": [
    "direct pdf w/ llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "S-c469oLmF2Z",
   "metadata": {
    "id": "S-c469oLmF2Z"
   },
   "outputs": [],
   "source": [
    "API_KEY=''\n",
    "modeltype= 'gpt-4-turbo-preview'\n",
    "main_dir=\"Docs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf266ec-2470-4752-b59c-7cf55e2fbac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rishikasrinivas/KnowledgeGraphMentalHealth\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771e04d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6771e04d",
    "outputId": "9cb6c35a-5f00-4481-9bb4-b791ad1db06a"
   },
   "outputs": [],
   "source": [
    "#pdf llm\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client= OpenAI( api_key= API_KEY)\n",
    "\n",
    "for filename in os.listdir(main_dir):\n",
    "    print(filename[-3:])\n",
    "    if filename[-3:] != 'pdf':\n",
    "        continue\n",
    "    filename= main_dir + filename\n",
    "    assistant_name= 'Clinicial Assistant'\n",
    "    \n",
    "    instructions=  \"\"\"\n",
    "      json: You are to extract important entities, their definitions, overarching ideas,  and their relationships with one another from this paper. Don't copy the sentence\n",
    "      word for word and split it up. Do not take all random relationships. Identify relationships that can help clinicians with diagnosis. GET THE \n",
    "      MAIN IDEA!!. Will/May need to look across sections.\n",
    "      \n",
    "      Understand the sentence and determine the relationships between the subject and objects\n",
    "    \n",
    "      DO NOT use the word 'Depression' ALONE as a subject or object. Each block of text emphasizes different types of depression and you must include the type of depression the relationship is referring to.\n",
    "      If the text is referring to all types of depression for that relationship, label it as \"All Depression\"\n",
    "      The idea is that these relationships can be pieced together into a knowledge graph that a clinician can trace. Keep this in mind as you extract.\n",
    "    \n",
    "      Do not use any relationships other than these: \n",
    "        1. treatment:  IPT --> treatment for -> depression\n",
    "        2. symptom: sadness -> symptom of -> depression\n",
    "        3. example: medA --> example of -> antidepressant\n",
    "        4. not effective: medA -> not effective for --> depression\n",
    "        5. effective: medA -> effective for -> depression\n",
    "        6. more effective: medA -> more effective than -> medB\n",
    "        7. less effective: medA -> less effective than -> medB\n",
    "        8. side effects: sneezing --> side effect of -> medA\n",
    "        9. treatment:  meditate --> treatment to -> reduce depression\n",
    "        10. Same efficacy: medA -> Same efficacy as -> no meds\n",
    "        11. Recommended first-line treatment: TreatA --> Recommended first-line treatment for --> illnesses\n",
    "        12. High Efficiency: MedA -> High Efficiency for -> DiseaseA\n",
    "        13. Less commonly used: MedB -> Less commonly used for -> Depression\n",
    "        14. correlated: DiseaseA -> correlated with -> ProblemA\n",
    "        15. More common than ... in ... : DiseaseA -> More common than -> DiseaseB -> in -> younger patients\n",
    "        16. Concurrent comorbidity: Disease A -> Concurrent comorbidity -> IllnessC\n",
    "        17. Results: DiseaseA -> results -> faster treatment in young people\n",
    "\n",
    "    Each of these relationships is the base from which you can deviate a bit. Ex you can say treatment for, treatment with, treats, etc but stick \n",
    "    to the base idea of treating. Same applies for all relations\n",
    "    \n",
    "      Example:  As shown in Table 2, remission rates were significantly lower in patients with anxious depression,\n",
    "      according to both the HAM-D criterion (22.2% versus 33.4%) and the QIDS-SR criterion (27.5% versus 38.9%). \n",
    "      Response rates were also significantly lower for patients with anxious depression (41.7% versus 52.8%). \"\n",
    "    \n",
    "      Gives the rel(s): Anxious Depression -> finding -> low remission rates  and Anxious Depression -> finding -> low response rates \n",
    "      \n",
    "      Present 1 dataframe in an easily readable and visually appealing format.\n",
    "      The dataframe should explain the relationships between all subjects.\n",
    "      It should have a 4 headers, subj, rel, obj, reference. Reference should hold the exact sentence(s) (in quotes) that you used to get the relationship\n",
    "      If you have object2 as a header, you must have a non-empty rel2 as a header. If thats not possible place the relationship in the next row\n",
    "    \n",
    "    \n",
    "      return a pandas dataframe structure called paper1\n",
    "      Return a form of a dictionary of lists.\n",
    "      Avoid entities and relationships that are more than a few words. If you need to list multiple drug names or treatments, list them in different rows\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    assistant= client.beta.assistants.create(\n",
    "    name= assistant_name,\n",
    "    instructions= instructions,\n",
    "    model= modeltype,\n",
    "    tools= [{\"type\":\"file_search\"}])\n",
    "    \n",
    "    message_file= client.files.create(\n",
    "    file=open(filename, \"rb\"),\n",
    "    purpose=\"assistants\")\n",
    "    thread= client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\": instructions,\n",
    "            \"attachments\":[\n",
    "                {\"file_id\": message_file.id,\n",
    "                \"tools\":[{\"type\":\"file_search\"}]}\n",
    "            ],\n",
    "    \n",
    "        }\n",
    "    ]\n",
    "                 )\n",
    "    \n",
    "    run= client.beta.threads.runs.create_and_poll(thread_id= thread.id, assistant_id= assistant.id)\n",
    "    \n",
    "    messages= list(client.beta.threads.messages.list(thread_id=thread.id, run_id= run.id))\n",
    "    message_content= messages[0].content[0].text\n",
    "    annotations= message_content.annotations\n",
    "    citations=[]\n",
    "    for index, annotation in enumerate(annotations):\n",
    "              message_content.valye= message_content.value .replace(annotation.text,\"\"). replace(\".\", \"\")\n",
    "              if file_citation :=getattr(annotations, \"file_citation\", None):\n",
    "                  cited_file= client.files.retrieve(file_citation.file.id)\n",
    "                  citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "    cand_name = message_content.value.replace(\".\", \"\"). strip()\n",
    "    print(cand_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PgRT7GB8d1Q2",
   "metadata": {
    "id": "PgRT7GB8d1Q2"
   },
   "source": [
    "nlp processing w/ llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56BTxF5Zd0sp",
   "metadata": {
    "id": "56BTxF5Zd0sp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf\n",
      "txt\n",
      "pdf\n",
      "nts\n",
      "txt\n",
      "txt\n",
      "pdf\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import os\n",
    "import pandas as pd\n",
    "texts=[]\n",
    "# Opening the PDF file\n",
    "skip=3\n",
    "for doc in os.listdir(main_dir):\n",
    "    print(doc[-3:])\n",
    "    if doc[-3:] != 'pdf':\n",
    "        continue\n",
    "    doc=fitz.open(main_dir+doc)\n",
    "    # Extracting text from all pages\n",
    "    all_text = []\n",
    "    for page_num in range(0,len(doc),skip):\n",
    "        tex=\"\"\n",
    "        for p in range(page_num, page_num+skip):\n",
    "          if p >= len(doc):\n",
    "            break\n",
    "          page = doc[p]\n",
    "          text = page.get_text().replace('\\n', ' ').lower()\n",
    "          docs=nlp(text)\n",
    "          text=\" \".join([token.lemma_ for token in docs])\n",
    "          tex += text\n",
    "        all_text.append([page_num + 1, tex])\n",
    "        df = pd.DataFrame(all_text, columns=['Page', 'Text'])\n",
    "        for text in df['Text'].to_list():\n",
    "            if 'References' in text or 'Received' in text:\n",
    "                break\n",
    "            texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31eaa7ab-2af3-49c9-ba5e-3f5c1a7767a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.4.1-cp312-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "Successfully installed torch-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "NyIIYYOvfPfO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyIIYYOvfPfO",
    "outputId": "50f4c5ab-b3e8-428c-85f2-0631881f3a8c"
   },
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLocalProtocolError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:72\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:93\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msend_request_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     92\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msend_request_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:151\u001b[0m, in \u001b[0;36mHTTP11Connection._send_request_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    149\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions({h11\u001b[38;5;241m.\u001b[39mLocalProtocolError: LocalProtocolError}):\n\u001b[1;32m    152\u001b[0m     event \u001b[38;5;241m=\u001b[39m h11\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    153\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    154\u001b[0m         target\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39murl\u001b[38;5;241m.\u001b[39mtarget,\n\u001b[1;32m    155\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    156\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(value)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m: Illegal header value b'Bearer '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:973\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 973\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    974\u001b[0m         request,\n\u001b[1;32m    975\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m    976\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m    927\u001b[0m     request,\n\u001b[1;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    931\u001b[0m )\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m    955\u001b[0m         request,\n\u001b[1;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    958\u001b[0m     )\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:235\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(value)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:89\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mLocalProtocolError\u001b[0m: Illegal header value b'Bearer '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m client\u001b[38;5;241m=\u001b[39m OpenAI( api_key\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      4\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      5\u001b[0m         {\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m             },\n\u001b[1;32m      9\u001b[0m         {\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m             }\n\u001b[1;32m     13\u001b[0m         ],\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39m modeltype,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py:679\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    677\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    678\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    680\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    681\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    682\u001b[0m             {\n\u001b[1;32m    683\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    687\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    688\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    689\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    690\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    691\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    692\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    693\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    694\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    695\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    696\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m    697\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    698\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    699\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m    700\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    701\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    702\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    703\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    704\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    705\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    706\u001b[0m             },\n\u001b[1;32m    707\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    708\u001b[0m         ),\n\u001b[1;32m    709\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    710\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    711\u001b[0m         ),\n\u001b[1;32m    712\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    713\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    714\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    715\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1259\u001b[0m     )\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    938\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    939\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    940\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    941\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    942\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[1;32m    943\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:997\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    994\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 997\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    998\u001b[0m         input_options,\n\u001b[1;32m    999\u001b[0m         cast_to,\n\u001b[1;32m   1000\u001b[0m         retries,\n\u001b[1;32m   1001\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1002\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1003\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1004\u001b[0m     )\n\u001b[1;32m   1006\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1076\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1077\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1078\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[1;32m   1079\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1080\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1081\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:997\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    994\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 997\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    998\u001b[0m         input_options,\n\u001b[1;32m    999\u001b[0m         cast_to,\n\u001b[1;32m   1000\u001b[0m         retries,\n\u001b[1;32m   1001\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1002\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1003\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1004\u001b[0m     )\n\u001b[1;32m   1006\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1076\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1077\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1078\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[1;32m   1079\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1080\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1081\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_base_client.py:1007\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    998\u001b[0m             input_options,\n\u001b[1;32m    999\u001b[0m             cast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m             response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1004\u001b[0m         )\n\u001b[1;32m   1006\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1011\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1015\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1016\u001b[0m )\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-request-id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "client= OpenAI( api_key= '')\n",
    "client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": 'prompt',\n",
    "            },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'answer the {prompt}',\n",
    "            }\n",
    "        ],\n",
    "    model= modeltype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "x4LC93L-H0Q7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4LC93L-H0Q7",
    "outputId": "ea7e08f1-2e8c-41f2-f3be-03cc95e08c18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport json\\nfor t in texts:\\n    prompt_llm= \"\"\"\\n    json: GET THE \\n    MAIN IDEA!! You are to extract important entities, their definitions, overarching ideas,  and their relationships with one another from this paper. Don\\'t copy the sentence\\n    word for word and split it up. Do not take all random relationships. Identify relationships that can help clinicians with diagnosis. . Will/May need to look across sections. Refrain from forming relationships unless text explicitly highlights or suggests that.\\n    \\n    For example, do not say a medicine is/isn\\'t effective unless the text explicity says so\\n    \\n    Understand the sentence and determine the relationships between the subject and objects\\n    \\n    DO NOT use the word \\'Depression\\' ALONE as a subject or object. Each block of text emphasizes different types of depression and you must include the type of depression the relationship is referring to.\\n    If the text is referring to all types of depression for that relationship, label it as \"All Depression\"\\n    The idea is that these relationships can be pieced together into a knowledge graph that a clinician can trace. Keep this in mind as you extract.\\n    \\n    Do not use any relationships other than these: \\n    1. treatment:  IPT --> treatment for -> depression\\n    2. symptom: sadness -> symptom of -> depression\\n    3. example: medA --> example of -> antidepressant\\n    4. not effective: medA -> not effective for --> depression\\n    5. effective: medA -> effective for -> depression\\n    6. more effective: medA -> more effective than -> medB\\n    7. less effective: medA -> less effective than -> medB\\n    7. as effective as : medA -> as effective as -> medB\\n    8. side effects: sneezing --> side effect of -> medA\\n    9. treatment:  meditate --> treatment to -> reduce depression\\n    10. Same efficacy: medA -> Same efficacy as -> no meds\\n    11. Recommended first-line treatment: TreatA --> Recommended first-line treatment for --> illnesses\\n    12. High Efficiency: MedA -> High Efficiency for -> DiseaseA\\n    13. Less commonly used: MedB -> Less commonly used for -> Depression\\n    14. correlated: DiseaseA -> correlated with -> ProblemA\\n    15. More common than ... in ... : DiseaseA -> More common than -> DiseaseB -> in -> younger patients\\n    16. Concurrent comorbidity: Disease A -> Concurrent comorbidity -> IllnessC\\n    17. results: DiseaseA -> results -> faster treatment in young people\\n    18. predictor of: use of medA -> predictor of -> diseaseB\\n    19. Associateed with: Disease A -> associted with -> diases B\\n    20. definition: therapyA -> definition -> defA\\n    21: Correlation: ilnnessA -> correlation -> ilnessB\\n    22. Most common treatment: DiseaseA -> Most common treatment -> MedA\\n    23. Second most common treatment: DiseaseA - Second most common treatment -> MedA\\n    24. Use: MedA -> use -> decreasing symptomA or medA -> used on -> patients with problem B\\n    25. Properties: medC -> properties -> reduces this symptom by inihibiting that neuron\\n    26: form of: IllnessA -> form of -> CategroyA\\n    26. goal: MedA -> goal -> reduce anger\\n    27: requirements: treatmentA -> requirements -> patient under 23\\n    \\n    \\n    THESE SHOULD NOT BE THE SUBJ OR OBJ!!\\n    Each of these relationships is the base from which you can deviate a bit. Ex you can say treatment for, treatment with, treats, etc but stick \\n    to the base idea of treating. Same applies for all relations    \\n\\n    Examples: \"bupropion is more likely than some ssris to lead to minimal weight gain or even weight loss.\"\\n        subj: bupropion \\n        rel: side effects \\n        obj: more likely than some ssris to lead to minimal weight gain or even weight loss minimal weight gain or even weight loss\\n    Examples: \"venlafaxine\\'s was seen to follow with less mental clarity than other medicines\"\\n        subj: venlafaxine\\n        rel: side effect\\n        obj: less mental clarity\\n\\n\\n\\n    Example:  As shown in Table 2, remission rates were significantly lower in patients with anxious depression,\\n    according to both the HAM-D criterion (22.2% versus 33.4%) and the QIDS-SR criterion (27.5% versus 38.9%). \\n    Response rates were also significantly lower for patients with anxious depression (41.7% versus 52.8%). \"\\n    \\n    Gives the rel(s): Anxious Depression -> finding -> low remission rates  and Anxious Depression -> finding -> low response rates \\n    \\n    Present 1 dataframe in an easily readable and visually appealing format.\\n    The dataframe should explain the relationships between all subjects.\\n    It should have a 4 headers, subj, rel, obj, reference. Reference should hold the exact sentence(s) (in quotes) that you used to get the relationship\\n    If you have object2 as a header, you must have a non-empty rel2 as a header. If thats not possible place the relationship in the next row\\n    \\n    \\n    return a pandas dataframe structure called paper1\\n    Return a form of a dictionary of lists.\\n    Avoid entities and relationships that are more than a few words. If you need to list multiple drug names or treatments, list them in different rows\\n    \\n    \\n    \"\"\"\\n    \\n    prompt=f\"Using this information: {t}, answer the following question: {prompt_llm}\"\\n\\n    chat_completion=client.chat.completions.create(\\n        temperature = 0.2,\\n        messages=[\\n            {\\n                \"role\": \"system\",\\n                \"content\": prompt_llm,\\n                },\\n            {\\n                \"role\": \"user\",\\n                \"content\": prompt,\\n                }\\n            ],\\n        model= modeltype,\\n    )\\n    resp=chat_completion.choices[0].message.content\\n    start_idx=resp.find(\"data = \")\\n    if resp[start_idx+7] == \\'[\\':\\n        end_idx=resp[start_idx:].find(\\']\\')\\n    else:\\n        end_idx=resp[start_idx:].find(\\'}\\')\\n    resp=resp[start_idx+7:start_idx+end_idx+1]\\n    print(eval(resp))\\n    \\n    df=pd.concat([df, pd.DataFrame(eval(resp))])\\n    df=df.drop_duplicates(subset=[\\'subj\\', \\'obj\\', \\'rel\\'], keep=\\'first\\')\\n    print(\"\\n\\n\\n\")\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client= OpenAI( api_key= API_KEY)\n",
    "\n",
    "import json\n",
    "for t in texts:\n",
    "    prompt_llm= \"\"\"\n",
    "    json: GET THE \n",
    "    MAIN IDEA!! You are to extract important entities, their definitions, overarching ideas,  and their relationships with one another from this paper. Don't copy the sentence\n",
    "    word for word and split it up. Do not take all random relationships. Identify relationships that can help clinicians with diagnosis. . Will/May need to look across sections. Refrain from forming relationships unless text explicitly highlights or suggests that.\n",
    "    \n",
    "    For example, do not say a medicine is/isn't effective unless the text explicity says so\n",
    "    \n",
    "    Understand the sentence and determine the relationships between the subject and objects\n",
    "    \n",
    "    DO NOT use the word 'Depression' ALONE as a subject or object. Each block of text emphasizes different types of depression and you must include the type of depression the relationship is referring to.\n",
    "    If the text is referring to all types of depression for that relationship, label it as \"All Depression\"\n",
    "    The idea is that these relationships can be pieced together into a knowledge graph that a clinician can trace. Keep this in mind as you extract.\n",
    "    \n",
    "    Do not use any relationships other than these: \n",
    "    1. treatment:  IPT --> treatment for -> depression\n",
    "    2. symptom: sadness -> symptom of -> depression\n",
    "    3. example: medA --> example of -> antidepressant\n",
    "    4. not effective: medA -> not effective for --> depression\n",
    "    5. effective: medA -> effective for -> depression\n",
    "    6. more effective: medA -> more effective than -> medB\n",
    "    7. less effective: medA -> less effective than -> medB\n",
    "    7. as effective as : medA -> as effective as -> medB\n",
    "    8. side effects: sneezing --> side effect of -> medA\n",
    "    9. treatment:  meditate --> treatment to -> reduce depression\n",
    "    10. Same efficacy: medA -> Same efficacy as -> no meds\n",
    "    11. Recommended first-line treatment: TreatA --> Recommended first-line treatment for --> illnesses\n",
    "    12. High Efficiency: MedA -> High Efficiency for -> DiseaseA\n",
    "    13. Less commonly used: MedB -> Less commonly used for -> Depression\n",
    "    14. correlated: DiseaseA -> correlated with -> ProblemA\n",
    "    15. More common than ... in ... : DiseaseA -> More common than -> DiseaseB -> in -> younger patients\n",
    "    16. Concurrent comorbidity: Disease A -> Concurrent comorbidity -> IllnessC\n",
    "    17. results: DiseaseA -> results -> faster treatment in young people\n",
    "    18. predictor of: use of medA -> predictor of -> diseaseB\n",
    "    19. Associateed with: Disease A -> associted with -> diases B\n",
    "    20. definition: therapyA -> definition -> defA\n",
    "    21: Correlation: ilnnessA -> correlation -> ilnessB\n",
    "    22. Most common treatment: DiseaseA -> Most common treatment -> MedA\n",
    "    23. Second most common treatment: DiseaseA - Second most common treatment -> MedA\n",
    "    24. Use: MedA -> use -> decreasing symptomA or medA -> used on -> patients with problem B\n",
    "    25. Properties: medC -> properties -> reduces this symptom by inihibiting that neuron\n",
    "    26: form of: IllnessA -> form of -> CategroyA\n",
    "    26. goal: MedA -> goal -> reduce anger\n",
    "    27: requirements: treatmentA -> requirements -> patient under 23\n",
    "    \n",
    "    \n",
    "    THESE SHOULD NOT BE THE SUBJ OR OBJ!!\n",
    "    Each of these relationships is the base from which you can deviate a bit. Ex you can say treatment for, treatment with, treats, etc but stick \n",
    "    to the base idea of treating. Same applies for all relations    \n",
    "\n",
    "    Examples: \"bupropion is more likely than some ssris to lead to minimal weight gain or even weight loss.\"\n",
    "        subj: bupropion \n",
    "        rel: side effects \n",
    "        obj: more likely than some ssris to lead to minimal weight gain or even weight loss minimal weight gain or even weight loss\n",
    "    Examples: \"venlafaxine's was seen to follow with less mental clarity than other medicines\"\n",
    "        subj: venlafaxine\n",
    "        rel: side effect\n",
    "        obj: less mental clarity\n",
    "\n",
    "\n",
    "\n",
    "    Example:  As shown in Table 2, remission rates were significantly lower in patients with anxious depression,\n",
    "    according to both the HAM-D criterion (22.2% versus 33.4%) and the QIDS-SR criterion (27.5% versus 38.9%). \n",
    "    Response rates were also significantly lower for patients with anxious depression (41.7% versus 52.8%). \"\n",
    "    \n",
    "    Gives the rel(s): Anxious Depression -> finding -> low remission rates  and Anxious Depression -> finding -> low response rates \n",
    "    \n",
    "    Present 1 dataframe in an easily readable and visually appealing format.\n",
    "    The dataframe should explain the relationships between all subjects.\n",
    "    It should have a 4 headers, subj, rel, obj, reference. Reference should hold the exact sentence(s) (in quotes) that you used to get the relationship\n",
    "    If you have object2 as a header, you must have a non-empty rel2 as a header. If thats not possible place the relationship in the next row\n",
    "    \n",
    "    \n",
    "    return a pandas dataframe structure called paper1\n",
    "    Return a form of a dictionary of lists.\n",
    "    Avoid entities and relationships that are more than a few words. If you need to list multiple drug names or treatments, list them in different rows\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    prompt=f\"Using this information: {t}, answer the following question: {prompt_llm}\"\n",
    "\n",
    "    chat_completion=client.chat.completions.create(\n",
    "        temperature = 0.2,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt_llm,\n",
    "                },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "        model= modeltype,\n",
    "    )\n",
    "    resp=chat_completion.choices[0].message.content\n",
    "    start_idx=resp.find(\"data = \")\n",
    "    if resp[start_idx+7] == '[':\n",
    "        end_idx=resp[start_idx:].find(']')\n",
    "    else:\n",
    "        end_idx=resp[start_idx:].find('}')\n",
    "    resp=resp[start_idx+7:start_idx+end_idx+1]\n",
    "    print(eval(resp))\n",
    "    \n",
    "    df=pd.concat([df, pd.DataFrame(eval(resp))])\n",
    "    df=df.drop_duplicates(subset=['subj', 'obj', 'rel'], keep='first')\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "799952e7-114e-43aa-8fa8-3556c6dca6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].map(str.lower) #.drop_duplicates(subset=['subj', 'rel', 'obj'])\n",
    "df = df.drop_duplicates(subset=['subj', 'rel', 'obj']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91d49f8e-8a3b-456c-9711-d945757b650b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>rel</th>\n",
       "      <th>obj</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ssris</td>\n",
       "      <td>recommended first-line treatment for</td>\n",
       "      <td>all depression</td>\n",
       "      <td>most guideline currently recommend ssris as th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tca</td>\n",
       "      <td>less effective than</td>\n",
       "      <td>ssris in hospitalized patients with severe mdd...</td>\n",
       "      <td>some tcas can be more effective than ssris whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maois</td>\n",
       "      <td>less commonly used for</td>\n",
       "      <td>all depression due to side effects</td>\n",
       "      <td>due to their side effects, maois have become l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>venlafaxine</td>\n",
       "      <td>as effective as</td>\n",
       "      <td>tcas</td>\n",
       "      <td>venlafaxine’s efficacy is comparable to that o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duloxetine</td>\n",
       "      <td>as effective as</td>\n",
       "      <td>ssris</td>\n",
       "      <td>in individual studies, venlafaxine and duloxet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>bupropion and ssris</td>\n",
       "      <td>effective for</td>\n",
       "      <td>major depressive disorder with high levels of ...</td>\n",
       "      <td>efficacy of bupropion and ssris in the treatme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>vilazodone, levomilnacipran, and vortioxetine</td>\n",
       "      <td>effective for</td>\n",
       "      <td>major depressive disorder</td>\n",
       "      <td>a review of the clinical efficacy, safety and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>trazodone</td>\n",
       "      <td>less commonly used for</td>\n",
       "      <td>depression</td>\n",
       "      <td>trazodone: a 5-year review of antidepressant e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ketamine</td>\n",
       "      <td>treatment for</td>\n",
       "      <td>treatment-resistant depression</td>\n",
       "      <td>a consensus statement on the use of ketamine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>intranasal esketamine</td>\n",
       "      <td>treatment for</td>\n",
       "      <td>treatment-resistant depression</td>\n",
       "      <td>intranasal esketamine: from origin to future i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              subj  \\\n",
       "0                                            ssris   \n",
       "1                                              tca   \n",
       "2                                            maois   \n",
       "3                                      venlafaxine   \n",
       "4                                       duloxetine   \n",
       "..                                             ...   \n",
       "221                            bupropion and ssris   \n",
       "222  vilazodone, levomilnacipran, and vortioxetine   \n",
       "223                                      trazodone   \n",
       "224                                       ketamine   \n",
       "225                          intranasal esketamine   \n",
       "\n",
       "                                      rel  \\\n",
       "0    recommended first-line treatment for   \n",
       "1                     less effective than   \n",
       "2                  less commonly used for   \n",
       "3                         as effective as   \n",
       "4                         as effective as   \n",
       "..                                    ...   \n",
       "221                         effective for   \n",
       "222                         effective for   \n",
       "223                less commonly used for   \n",
       "224                         treatment for   \n",
       "225                         treatment for   \n",
       "\n",
       "                                                   obj  \\\n",
       "0                                       all depression   \n",
       "1    ssris in hospitalized patients with severe mdd...   \n",
       "2                   all depression due to side effects   \n",
       "3                                                 tcas   \n",
       "4                                                ssris   \n",
       "..                                                 ...   \n",
       "221  major depressive disorder with high levels of ...   \n",
       "222                          major depressive disorder   \n",
       "223                                         depression   \n",
       "224                     treatment-resistant depression   \n",
       "225                     treatment-resistant depression   \n",
       "\n",
       "                                             reference  \n",
       "0    most guideline currently recommend ssris as th...  \n",
       "1    some tcas can be more effective than ssris whe...  \n",
       "2    due to their side effects, maois have become l...  \n",
       "3    venlafaxine’s efficacy is comparable to that o...  \n",
       "4    in individual studies, venlafaxine and duloxet...  \n",
       "..                                                 ...  \n",
       "221  efficacy of bupropion and ssris in the treatme...  \n",
       "222  a review of the clinical efficacy, safety and ...  \n",
       "223  trazodone: a 5-year review of antidepressant e...  \n",
       "224  a consensus statement on the use of ketamine i...  \n",
       "225  intranasal esketamine: from origin to future i...  \n",
       "\n",
       "[226 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"Saved_Rels.csv\")\n",
    "df=df.drop(columns=['index','Unnamed: 0'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc27c4a-e2a6-4425-a9c0-1f5d334ddd67",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d97f82-bd0b-4e33-abb1-15891d3fd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LangChainStringEvaluator(\"string_distance\", config={\"distance\": \"damerau_levenshtein\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZUz3T7eLoPu7",
   "metadata": {
    "id": "ZUz3T7eLoPu7"
   },
   "outputs": [],
   "source": [
    "!git branch main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6V4n1eEJsdpz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6V4n1eEJsdpz",
    "outputId": "8a82a42a-c0fd-4169-81b9-d8413c78b261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K1DA7z1roPzH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1DA7z1roPzH",
    "outputId": "e6166729-3b48-40bd-f602-bc50216a7728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: pathspec 'Brightside' did not match any files\n",
      "error: remote origin already exists.\n",
      "On branch master\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mKnowledgeGraphMentalHealth/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n",
      "fatal: could not read Username for 'https://github.com': No such device or address\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git add /content/\n",
    "!git remote add origin \"https://github.com/rishikasrinivas/KnowledgeGraphMentalHealth.git\"\n",
    "!git config --global user.email \"you@example.com\"\n",
    "!git config --global user.name \"Your Name\"\n",
    "!git commit -m \"GPT code w/ trial kg\"\n",
    "!git push -u origin main"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
